# s2_intra_oyster_segmentation.py
#
# Description:
# This script performs Stage 2 of the oyster analysis pipeline. It is designed
# to run after s1_oyster_instance_segmentation.py.
#
# For each WSI processed in Stage 1, this script will:
# 1. Locate the original high-resolution WSI file.
# 2. Find all the individual oyster instance masks generated by SAM in Stage 1.
# 3. For each oyster mask:
#    a. Determine the best magnification level in the WSI for analysis.
#    b. Scale the low-resolution Stage 1 mask up to the resolution of the chosen WSI level.
#    c. Generate a grid of coordinates for high-resolution patches that fall within the scaled mask.
#    d. Read each patch from the WSI file on-demand to keep memory usage low.
#    e. Use SAM's AutomaticMaskGenerator to find all segmentable features within each patch.
#    f. Save the resulting sub-masks and visualization overlays for each patch.
#
# Usage:
# 1. Ensure Stage 1 has been run and its output directory is populated.
# 2. Update the configuration variables in the SCRIPT_CONFIG section.
# 3. Run the script: python s2_intra_oyster_segmentation.py

import numpy as np
import os
import cv2
import matplotlib.pyplot as plt
import torch
import tifffile
from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator
import logging
import time
import glob

# torch.set_default_dtype(torch.float32)

# --- SCRIPT CONFIGURATION ---
# Paths
ORIGINAL_WSI_DIR = "/Volumes/One Touch/MSX Project/TIFF/test" # Directory containing the original, high-res WSI files
STAGE1_OUTPUT_PARENT_DIR = "output_stage1_masks_logging"      # The main output directory from s1_oyster_instance_segmentation.py
SAM_CHECKPOINT_PATH = "pretrained_checkpoint/sam_vit_h_4b8939.pth"
SAM_MODEL_TYPE = "vit_h"
OUTPUT_DIR_STAGE2 = "output_stage2_intra_oyster" # Parent directory for all Stage 2 outputs

# WSI & Patching Parameters
TARGET_MAGNIFICATION = 20.0         # Desired magnification for analysis (e.g., 5.0, 10.0, 20.0)
PATCH_SIZE = 512                    # Pixel size of square patches to extract (e.g., 256, 512, 1024)
PATCH_OVERLAP = 64                  # Overlap between patches (e.g., 0 for no overlap, or a portion of patch_size)
TISSUE_IN_PATCH_THRESHOLD = 0.1     # Min percentage of tissue required in a patch to be considered valid (0.0 to 1.0)
MANUAL_WSI_OBJECTIVE_POWER = 20.0   # Example: if scanned at 20x. Set to None if available in WSI.

# This MUST match the downsample factor used to generate the low-res image in Stage 1
STAGE1_PROCESSING_DOWNSAMPLE = 32.0

# Control plotting for debugging (can slow down batch processing significantly)
ENABLE_PLOTTING = False
# Limit number of patches to process per oyster for quick testing. Set to a high number (e.g., 99999) to process all.
MAX_PATCHES_TO_PROCESS_PER_OYSTER = 10
# --- END SCRIPT CONFIGURATION ---

# --- Global Logger ---
logger = logging.getLogger(__name__)

def setup_logging_s2(log_dir):
    """
    Configures logging to console and file for Stage 2.

    :param log_dir: Directory where log files will be saved.
    """
    os.makedirs(log_dir, exist_ok=True)
    timestamp = time.strftime("%Y%m%d-%H%M%S")
    log_file_path = os.path.join(log_dir, f"stage2_processing_{timestamp}.log")

    # Remove existing handlers to avoid duplicate logs if re-running in the same session
    if logger.hasHandlers():
        logger.handlers.clear()

    logger.setLevel(logging.DEBUG)

    # Console Handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO) # Show INFO and above on console for cleaner output
    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)

    # File Handler
    file_handler = logging.FileHandler(log_file_path)
    file_handler.setLevel(logging.DEBUG) # Log DEBUG and above to file
    file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(file_formatter)
    logger.addHandler(file_handler)

    logger.info("Stage 2 logging setup complete. Log file: %s", log_file_path)


# --- Helper Functions ---
def load_sam_automask_generator(checkpoint_path,
                                model_type,
                                points_per_side=32,
                                pred_iou_thresh=0.88,
                                stability_score_thresh=0.95,
                                min_mask_region_area=100):
    """
    Initializes and returns the SAM AutomaticMaskGenerator.

    :param checkpoint_path: Path to the SAM model checkpoint.
    :param model_type: Type of SAM model (e.g., "vit_h").
    :param points_per_side: Number of points per side for mask generation.
    :param pred_iou_thresh: Prediction IoU threshold.
    :param stability_score_thresh: Stability score threshold.
    :param min_mask_region_area: Minimum area for mask regions.

    :return: Initialized SamAutomaticMaskGenerator instance or None if failed.
    """
    device = "mps" if torch.backends.mps.is_available() else ("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"Using SAM device for AutomaticMaskGenerator: {device}")
    try:
        logger.info("Loading SAM model for AutomaticMaskGenerator...")
        sam_model = sam_model_registry[model_type](checkpoint=checkpoint_path)
        sam_model.to(device=device)
        mask_generator = SamAutomaticMaskGenerator(
            model=sam_model,
            points_per_side=points_per_side,
            pred_iou_thresh=pred_iou_thresh,
            stability_score_thresh=stability_score_thresh,
            min_mask_region_area=min_mask_region_area
        )
        logger.info("SAM AutomaticMaskGenerator loaded successfully.")
        return mask_generator
    except FileNotFoundError:
        logger.error(f"🛑 SAM Checkpoint not found at {checkpoint_path}.")
    except Exception as e:
        logger.error(f"🛑 Error loading SAM model for AutomaticMaskGenerator: {e}", exc_info=True)
    return None

def load_ome_tiff_pyramid(wsi_path, manual_objective_power=None):
    """
    Loads an OME-TIFF file and extracts its pyramid structure.

    :param wsi_path: Path to the OME-TIFF file.
    :param manual_objective_power: Manual override for objective power if not found in WSI properties.
    :return: Tuple containing: (tifffile.TiffFile object, base magnification, list of level dimensions (width, height), list of downsample factors).
    """
    logger.info(f"Loading OME-TIFF with tifffile: {wsi_path}")
    try:
        tif = tifffile.TiffFile(wsi_path)
        if not tif.is_ome:
            logger.warning("TIFF file does not appear to be an OME-TIFF according to tifffile.")

        base_magnification = float(manual_objective_power) if manual_objective_power else None
        main_series = tif.series[0]
        num_levels = len(main_series.levels)
        logger.info(f"Series 0 has {num_levels} levels.")

        level_dimensions_wh, level_downsamples = [], []
        base_width, base_height = main_series.levels[0].shape[1], main_series.levels[0].shape[0]

        for i, level in enumerate(main_series.levels):
            lvl_shape = level.shape
            level_dimensions_wh.append((lvl_shape[1], lvl_shape[0]))
            ds = base_width / lvl_shape[1] if lvl_shape[1] > 0 else 1.0
            level_downsamples.append(ds)

        logger.info(f"  Processed level dimensions (W,H): {level_dimensions_wh}")
        logger.info(f"  Calculated level downsamples: {[round(ds, 2) for ds in level_downsamples]}")
        return tif, base_magnification, level_dimensions_wh, level_downsamples
    except Exception as e:
        logger.error(f"🛑 Error opening/processing OME-TIFF with tifffile: {e}", exc_info=True)
        return None, None, [], []

def load_stage1_instance_mask(mask_path):
    """
    Loads the instance mask from Stage 1.

    :param mask_path: Path to the instance mask image file.
    :return: Binary mask image (numpy array) or None if loading failed.
    """
    logger.info(f"Loading Stage 1 instance mask: {mask_path}")
    mask_low_res = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask_low_res is None:
        logger.error(f"🛑 Instance mask {mask_path} not found or could not be loaded.")
        return None
    _, mask_low_res_binary = cv2.threshold(mask_low_res, 127, 255, cv2.THRESH_BINARY)
    logger.debug(f"Instance mask loaded, shape: {mask_low_res_binary.shape}")
    return mask_low_res_binary

def get_level_for_target_mag(base_mag, target_mag, known_downsamples):
    """
    Determines the best WSI level index and downsample factor for the target magnification.

    :param base_mag: The base magnification of the WSI.
    :param target_mag: The target magnification for analysis.
    :param known_downsamples: List of known downsample factors for the WSI levels.
    :return: Tuple containing the best level index and its downsample factor.
    """
    if not base_mag or not target_mag: return 0, known_downsamples[0]
    ideal_downsample = base_mag / target_mag
    # Find the level with the downsample rate closest to, but not exceeding, the ideal one.
    best_level_idx = -1
    for i, ds in enumerate(known_downsamples):
        if ds <= ideal_downsample:
            best_level_idx = i
        else:
            break
    if best_level_idx == -1:  # If all downsamples are > ideal, pick the highest res available
        best_level_idx = 0
    return best_level_idx, known_downsamples[best_level_idx]

def show_anns(anns, ax):
    """
    Helper function to display masks from SamAutomaticMaskGenerator.

    :param anns: List of annotations (masks) to display.
    :param ax: Matplotlib axis to draw the masks on.
    """
    if not anns: return
    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)
    for ann in sorted_anns:
        m = ann['segmentation']
        color_mask = np.concatenate([np.random.random(3), [0.35]])
        ax.imshow(np.dstack((np.zeros_like(m, dtype=np.uint8), np.zeros_like(m, dtype=np.uint8),
                             np.zeros_like(m, dtype=np.uint8), m * color_mask[3] * 255)).astype('uint8'))

def find_wsi_file_by_basename(wsi_dir, base_name):
    """
    Searches for a WSI file in the specified directory by its base name.

    :param wsi_dir: Directory where WSI files are stored.
    :param base_name: Base name of the WSI file to search for (without extension).
    :return: Full path to the WSI file if found, otherwise None.
    """
    for ext in (".tif", ".tiff", ".vsi", ".svs"):  # Add other WSI extensions if needed
        potential_file = os.path.join(wsi_dir, base_name + ext)
        if os.path.exists(potential_file):
            return potential_file
        # Handle cases where s1 might have altered the name slightly, like replacing " - "
    for f in os.listdir(wsi_dir):
        if os.path.splitext(f)[0] == base_name:
            return os.path.join(wsi_dir, f)
    return None

# --- Main Processing Function for Single Oyster ---
def process_single_oyster_instance(wsi_file_path, instance_mask_path, sam_mask_generator, output_dir_s2_parent):
    """
    Processes a single oyster instance by:
    1. Loading the WSI and its properties.
    2. Loading the specific oyster instance mask.
    3. Determining the best patching level and scaling the mask.
    4. Loading the entire image plane for patching.
    5. Generating patch coordinates and extracting valid patches.
    6. Processing valid patches with SAM AutomaticMaskGenerator.
    7. Saving the resulting sub-masks and visualizations.
    This function is designed to be called for each oyster instance found in Stage 1.

    :param wsi_file_path: The path to the original WSI file.
    :param instance_mask_path: The path to the specific oyster instance mask generated in Stage 1.
    :param sam_mask_generator: An instance of SamAutomaticMaskGenerator for generating masks.
    :param output_dir_s2_parent: The parent directory where Stage 2 outputs will be saved.
    """
    wsi_base_name = os.path.splitext(os.path.basename(wsi_file_path))[0]
    mask_base_name = os.path.splitext(os.path.basename(instance_mask_path))[0]

    # Create a unique output directory for this specific oyster mask
    instance_output_dir = os.path.join(output_dir_s2_parent, wsi_base_name, mask_base_name)
    os.makedirs(instance_output_dir, exist_ok=True)
    logger.info(f"Output for this instance will be saved in: {instance_output_dir}")

    # 1. Load WSI and its properties
    wsi_file_obj, base_wsi_mag, wsi_level_dims, wsi_level_ds = load_ome_tiff_pyramid(
        wsi_file_path, MANUAL_WSI_OBJECTIVE_POWER
    )
    if not wsi_file_obj:
        logger.error(f"🛑 WSI could not be loaded for {wsi_file_path}. Aborting this instance.")
        return

    # 2. Load the specific oyster instance mask
    oyster_mask_s1_res = load_stage1_instance_mask(instance_mask_path)
    if oyster_mask_s1_res is None:
        wsi_file_obj.close()
        return

    # 3. Determine best patching level and scale the mask
    best_level, actual_ds = get_level_for_target_mag(base_wsi_mag, TARGET_MAGNIFICATION, wsi_level_ds)
    effective_mag = base_wsi_mag / actual_ds
    dims_of_patch_level = wsi_level_dims[best_level]

    logger.info(
        f"Best WSI level for patching: {best_level} (Downsample: {actual_ds:.2f}x, Effective Mag: {effective_mag:.2f}x)")

    logger.debug(
        f"Scaling Stage 1 mask to Level {best_level} resolution ({dims_of_patch_level[0]}x{dims_of_patch_level[1]})")
    scaled_mask = cv2.resize(oyster_mask_s1_res, dims_of_patch_level, interpolation=cv2.INTER_NEAREST)
    _, scaled_mask_binary = cv2.threshold(scaled_mask, 127, 255, cv2.THRESH_BINARY)

    # 4. Load the entire image plane for patching to avoid repeated reads
    try:
        logger.info(f"Loading entire image plane for WSI Level {best_level}...")
        image_plane = wsi_file_obj.series[0].levels[best_level].asarray()
        if image_plane.ndim == 3 and image_plane.shape[2] == 4:
            image_plane = cv2.cvtColor(image_plane, cv2.COLOR_RGBA2RGB)
        elif image_plane.ndim != 3 or image_plane.shape[2] != 3:
            image_plane = cv2.cvtColor(image_plane, cv2.COLOR_GRAY2RGB)  # Ensure 3 channels for SAM
        logger.info(f"Successfully loaded image plane for patching, shape: {image_plane.shape}")
    except Exception as e:
        logger.error(f"🛑 Error loading image plane for level {best_level}: {e}", exc_info=True)
        wsi_file_obj.close()
        return

    # 5. Generate patch coordinates and extract valid patches
    logger.info("Generating and validating patch coordinates...")
    valid_patches_info = []
    level_h, level_w = dims_of_patch_level[1], dims_of_patch_level[0]
    step_size = PATCH_SIZE - PATCH_OVERLAP

    for y in range(0, level_h - PATCH_SIZE + 1, step_size):
        for x in range(0, level_w - PATCH_SIZE + 1, step_size):
            mask_patch = scaled_mask_binary[y:y + PATCH_SIZE, x:x + PATCH_SIZE]
            if cv2.countNonZero(mask_patch) > (PATCH_SIZE * PATCH_SIZE * TISSUE_IN_PATCH_THRESHOLD):
                image_patch = image_plane[y:y + PATCH_SIZE, x:x + PATCH_SIZE, :]
                valid_patches_info.append({
                    "x": x, "y": y,
                    "prefix": f"patch_lvl{best_level}_x{x}_y{y}",
                    "data": image_patch
                })

    logger.info(f"Found {len(valid_patches_info)} valid patches to process.")

    # 6. Process valid patches with SAM AutomaticMaskGenerator
    num_to_process = min(MAX_PATCHES_TO_PROCESS_PER_OYSTER, len(valid_patches_info))
    logger.info(f"Processing first {num_to_process} patches with SAM...")

    for i, patch_info in enumerate(valid_patches_info[:num_to_process]):
        patch_image = patch_info['data']
        patch_prefix = patch_info['prefix']
        logger.debug(f"  Processing patch {i + 1}/{num_to_process}: {patch_prefix}")

        try:
            generated_masks = sam_mask_generator.generate(patch_image)
            logger.debug(f"    SAM generated {len(generated_masks)} masks for this patch.")

            if generated_masks:
                patch_output_dir = os.path.join(instance_output_dir, patch_prefix)
                os.makedirs(patch_output_dir, exist_ok=True)

                # Save individual masks
                for j, ann in enumerate(generated_masks):
                    mask_filename = f"mask_{j:03d}_area_{ann['area']}_iou_{ann['predicted_iou']:.2f}.png"
                    cv2.imwrite(os.path.join(patch_output_dir, mask_filename),
                                ann['segmentation'].astype(np.uint8) * 255)

                # Save visualization
                fig, ax = plt.subplots(figsize=(8, 8))
                ax.imshow(patch_image.astype('uint8'))
                show_anns(generated_masks, ax)
                ax.set_title(f"SAM Auto-Masks for {patch_prefix}")
                ax.axis('off')
                plt.savefig(os.path.join(patch_output_dir, f"{patch_prefix}_overlay.png"))
                plt.close(fig)  # Important to free memory
        except Exception as e:
            logger.error(f"🛑 Error during SAM processing for patch {patch_prefix}: {e}", exc_info=True)

    logger.info(f"--- Finished processing instance: {mask_base_name} ---")
    wsi_file_obj.close()
    logger.debug("Closed WSI file object.")

# --- Main Execution ---
if __name__ == "__main__":
    setup_logging_s2(OUTPUT_DIR_STAGE2)
    logger.info("--- Stage 2: Intra-Oyster Region Segmentation (Batch Processing) ---")

    # Initialize SAM once for the whole batch
    shared_sam_mask_generator = load_sam_automask_generator(SAM_CHECKPOINT_PATH, SAM_MODEL_TYPE)
    if not shared_sam_mask_generator:
        logger.critical("🛑 SAM AutomaticMaskGenerator could not be initialized. Exiting.")
        exit(1)

    # Find all processed WSI directories from Stage 1
    if not os.path.isdir(STAGE1_OUTPUT_PARENT_DIR):
        logger.critical(f"🛑 Stage 1 output directory not found at: {STAGE1_OUTPUT_PARENT_DIR}")
        exit(1)

    s1_processed_dirs = [d for d in os.listdir(STAGE1_OUTPUT_PARENT_DIR) if os.path.isdir(os.path.join(STAGE1_OUTPUT_PARENT_DIR, d))]
    logger.info(f"Found {len(s1_processed_dirs)} processed WSI directories from Stage 1.")

    for s1_dir_name in s1_processed_dirs:
        logger.info(f"\n>>> Checking Stage 1 output directory: {s1_dir_name}")

        # Find the corresponding original WSI file
        original_wsi_path = find_wsi_file_by_basename(ORIGINAL_WSI_DIR, s1_dir_name)
        if not original_wsi_path:
            logger.warning(f"  - Could not find matching original WSI for '{s1_dir_name}' in '{ORIGINAL_WSI_DIR}'. Skipping.")
            continue
        logger.info(f"  + Found corresponding WSI: {original_wsi_path}")

        # Find all SAM-generated instance masks for this WSI
        masks_dir = os.path.join(STAGE1_OUTPUT_PARENT_DIR, s1_dir_name, "sam_generated_masks")
        if not os.path.isdir(masks_dir):
            logger.info(f"  - No 'sam_generated_masks' sub-folder found for {s1_dir_name}. Skipping.")
            continue

        oyster_mask_files = glob.glob(os.path.join(masks_dir, "*_sam_mask_*.png"))
        logger.info(f"  + Found {len(oyster_mask_files)} oyster instance masks to process.")

        # Process each oyster mask individually
        for mask_path in oyster_mask_files:
            process_single_oyster_instance(
                original_wsi_path,
                mask_path,
                shared_sam_mask_generator,
                OUTPUT_DIR_STAGE2
            )

    logger.info("\n--- Fin ---")






# def load_sam_predictor(checkpoint_path, model_type):
#     """Initializes and returns the SAM predictor."""
#     device = "mps" if torch.backends.mps.is_available() else ("cuda" if torch.cuda.is_available() else "cpu")
#     print(f"Using SAM device: {device}")
#     try:
#         print("Loading SAM model for predictor...")
#         sam_model = sam_model_registry[model_type](checkpoint=checkpoint_path)
#         sam_model.to(device=device)
#         predictor = SamPredictor(sam_model)
#         print("SAM predictor loaded successfully.")
#         return predictor
#     except FileNotFoundError:
#         print(f"🛑 SAM Checkpoint not found at {checkpoint_path}.")
#     except Exception as e:
#         print(f"🛑 Error loading SAM model for predictor: {e}")
#     return None
#
# def load_wsi(wsi_path, manual_objective_power=None):
#     """Loads the WSI using OpenSlide and prints its properties."""
#     print(f"Loading WSI: {wsi_path}")
#     try:
#         wsi = openslide.OpenSlide(wsi_path)
#         print("WSI loaded successfully.")
#         print(f"  Level count: {wsi.level_count}")
#         print(f"  Level dimensions: {wsi.level_dimensions}")
#         print(f"  Level downsamples: {wsi.level_downsamples}")
#
#         objective_power_prop = openslide.PROPERTY_NAME_OBJECTIVE_POWER
#         if objective_power_prop in wsi.properties:
#             base_magnification = float(wsi.properties[objective_power_prop])
#             print(f"  Objective Power (from WSI properties): {base_magnification}x")
#         elif manual_objective_power is not None:
#             base_magnification = float(manual_objective_power)
#             print(f"  Objective Power (manual override): {base_magnification}x")
#         else:
#             base_magnification = None
#             print(f"  🛑 WARNING: Objective Power not found in WSI properties and not manually set.")
#             print(f"     Cannot accurately determine magnification levels without it.")
#         return wsi, base_magnification
#     except openslide.OpenSlideError as e:
#         print(f"🛑 Error opening WSI {wsi_path}: {e}")
#     except Exception as e:
#         print(f"🛑 An unexpected error occurred while opening WSI: {e}")
#     return None, None
#
# def load_ome_tiff_pyramid(wsi_path, manual_objective_power=None):
#     print(f"Loading OME-TIFF with tifffile: {wsi_path}")
#     try:
#         tif = tifffile.TiffFile(wsi_path) # Open the file
#
#         if not tif.is_ome:
#             print("Warning: TIFF file does not appear to be an OME-TIFF according to tifffile.")
#
#         base_magnification = None
#         if manual_objective_power:
#             base_magnification = float(manual_objective_power)
#             print(f"  Using manual objective power: {base_magnification}x")
#
#         num_series = len(tif.series)
#         print(f"  Tifffile found {num_series} series.")
#         if num_series == 0:
#             print("🛑 No series found in TIFF file.")
#             tif.close() # Close file before returning
#             return None, None, [], []
#
#         main_series = tif.series[0]
#         num_levels = len(main_series.levels)
#         print(f"  Series 0 has {num_levels} levels (IFDs/pages).")
#         # print(f"  Series 0 level dimensions (H,W,C from tifffile): {[level.shape for level in main_series.levels]}")
#
#         level_dimensions_wh = [] # Store as (Width, Height)
#         level_downsamples = []
#
#         if num_levels > 0:
#             expected_downsamples_from_qupath = [1, 2, 4, 8, 16, 32, 64, 128, 256]
#             for i in range(min(num_levels, len(expected_downsamples_from_qupath))):
#                 lvl_shape = main_series.levels[i].shape # H, W, [C]
#                 level_dimensions_wh.append((lvl_shape[1], lvl_shape[0])) # W, H
#                 level_downsamples.append(float(expected_downsamples_from_qupath[i]))
#         else:
#             print(f"🛑 No levels found in series 0.")
#             tif.close()
#             return None, None, [], []
#
#
#         print(f"  Processed level dimensions (W,H): {level_dimensions_wh}")
#         print(f"  Processed level downsamples: {level_downsamples}")
#
#         # For now, we return the TiffFile object itself so we can use it later to read regions.
#         # The caller will be responsible for closing it.
#         # Or, we can pass the main_series object.
#         return tif, base_magnification, level_dimensions_wh, level_downsamples
#
#     except Exception as e:
#         print(f"🛑 Error opening/processing OME-TIFF with tifffile: {e}")
#         if 'tif' in locals() and tif: # Ensure tif is defined and not None
#             try:
#                 tif.close()
#             except: pass
#     return None, None, [], []
#
# def load_stage1_instance_mask(mask_dir, mask_filename, expected_stage1_downsample_factor):
#     """Loads the instance mask from Stage 1 and its corresponding downsample factor."""
#     instance_mask_path = os.path.join(mask_dir, mask_filename)
#     print(f"Loading Stage 1 instance mask: {instance_mask_path}")
#     mask_low_res = cv2.imread(instance_mask_path, cv2.IMREAD_GRAYSCALE)
#
#     if mask_low_res is None:
#         print(f"🛑 Instance mask {instance_mask_path} not found or could not be loaded.")
#         return None
#     else:
#         # Ensure it's binary 0 or 255
#         _, mask_low_res_binary = cv2.threshold(mask_low_res, 127, 255, cv2.THRESH_BINARY)
#         print(f"Instance mask loaded, shape: {mask_low_res_binary.shape}")
#         if ENABLE_PLOTTING:
#             plt.figure(figsize=(6,6))
#             plt.imshow(mask_low_res_binary, cmap='gray')
#             plt.title(f"Loaded Stage 1 Mask: {mask_filename}")
#             plt.show()
#         return mask_low_res_binary
#
# def get_level_for_target_mag(base_mag, target_mag, known_downsamples):
#     """Determines the best WSI level index and downsample factor"""
#     if not base_mag or not target_mag:
#         return 0, 1.0 # Default to level 0, downsample 1.0
#     if target_mag > base_mag:
#         print(f"Warning: Target magnification {target_mag}x is higher than base {base_mag}x. Using base.")
#         return 0, 1.0
#
#     ideal_downsample = base_mag / target_mag
#     best_level_idx = 0
#     smallest_diff = float('inf')
#
#     closest_downsample = 1.0
#     for i, ds in enumerate(known_downsamples):
#         if ds <= ideal_downsample:
#             if (ideal_downsample - ds) < smallest_diff:
#                 smallest_diff = ideal_downsample - ds
#                 best_level_idx = i
#                 closest_downsample = ds
#         else: # ds > ideal_downsample, if we haven't found one yet, previous one is best
#             if smallest_diff == float('inf'): # If all known_downsamples are > ideal
#                 best_level_idx = i # Pick the smallest downsample available
#                 closest_downsample = ds
#             break # Stop, as downsamples are increasing
#
#     # If no suitable downsample was found (e.g. ideal_downsample is very small)
#     if smallest_diff == float('inf') and len(known_downsamples) > 0:
#         best_level_idx = 0
#         closest_downsample = known_downsamples[0]
#
#     return best_level_idx, closest_downsample
#
# def load_sam_automask_generator(
#         checkpoint_path,
#         model_type,
#         points_per_side=32,
#         pred_iou_thresh=0.88,
#         stability_score_thresh=0.95,
#         min_mask_region_area=100,
#         points_per_batch=64,
#         box_nms_thresh=0.7,
#         crop_n_layers=0,
#         crop_nms_thresh=0.7,
#         output_mode="binary_mask"
# ):
#     """Initializes and returns the SAM AutomaticMaskGenerator."""
#     device = "mps" if torch.backends.mps.is_available() else ("cuda" if torch.cuda.is_available() else "cpu")
#     print(f"Using SAM device for AutomaticMaskGenerator: {device}")
#     try:
#         print("Loading SAM model for AutomaticMaskGenerator...")
#         sam_model = sam_model_registry[model_type](checkpoint=checkpoint_path)
#         if device == "mps":
#             sam_model.to(torch.float32)  # Ensure model parameters are float32 before moving to MPS
#             # print("  ⚠️ Note: MPS backend requires float32 precision for SAM models.")
#             mask_generator = SamAutomaticMaskGenerator(
#                 model=sam_model,
#                 points_per_side=points_per_side,
#                 pred_iou_thresh=pred_iou_thresh,
#                 stability_score_thresh=stability_score_thresh,
#                 min_mask_region_area=min_mask_region_area,
#                 points_per_batch=points_per_batch,
#                 box_nms_thresh=box_nms_thresh,
#                 crop_n_layers=crop_n_layers,
#                 crop_nms_thresh=crop_nms_thresh,
#                 output_mode=output_mode,
#             )
#         sam_model.to(device=device)
#         print("SAM AutomaticMaskGenerator loaded successfully.")
#         return mask_generator
#     except FileNotFoundError:
#         print(f"🛑 SAM Checkpoint not found at {checkpoint_path}.")
#     except Exception as e:
#         print(f"🛑 Error loading SAM model for AutomaticMaskGenerator: {e}")
#     return None
#
# # def show_anns(anns, ax):
# #     """Helper function to display masks from SamAutomaticMaskGenerator."""
# #     if len(anns) == 0:
# #         return
# #     sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)
# #     # ax.set_autoscale_on(False) # Deprecated
# #     for annotation in sorted_anns:
# #         m = annotation['segmentation'] # This is a boolean mask
# #         img = np.ones((m.shape[0], m.shape[1], 3))
# #         color_mask = np.random.random((1, 3)).tolist()[0] # Random color for each mask
# #         for i in range(3):
# #             img[:,:,i] = color_mask[i]
# #         ax.imshow(np.dstack((img, m*0.35))) # Show mask with some transparency
#
#
# # --- Main Execution ---
# if __name__ == "__main__":
#     print("--- Stage 2: Intra-Oyster Region Segmentation ---")
#     os.makedirs(OUTPUT_DIR_STAGE2, exist_ok=True)
#
#     # 1. Load SAM (Predictor for later, MaskGenerator for now)
#     # sam_predictor = load_sam_predictor(SAM_CHECKPOINT_PATH, SAM_MODEL_TYPE)
#     # if not sam_predictor:
#     #     print("🛑 SAM Predictor could not be initialized. Exiting.")
#     #     exit()
#
#     sam_mask_generator = load_sam_automask_generator(SAM_CHECKPOINT_PATH, SAM_MODEL_TYPE)
#     if not sam_mask_generator:
#         print("🛑 SAM AutomaticMaskGenerator could not be initialized. Exiting.")
#         exit()
#
#     # 2. Load the original WSI
#     wsi_file_obj, base_wsi_magnification, wsi_level_dimensions, wsi_level_downsamples = load_ome_tiff_pyramid(
#         ORIGINAL_WSI_PATH,
#         MANUAL_WSI_OBJECTIVE_POWER
#     )
#
#     if not wsi_file_obj:
#         print("🛑 WSI could not be loaded. Exiting.")
#         exit()
#
#     # 3. Load the target oyster instance mask from Stage 1
#     oyster_instance_mask_stage1_res = load_stage1_instance_mask(
#         STAGE1_MASK_DIR,
#         TARGET_INSTANCE_MASK_FILENAME,
#         STAGE1_DOWNSAMPLE_FACTOR
#     )
#     if oyster_instance_mask_stage1_res is None:
#         wsi_file_obj.close()  # Close the WSI file if we exit
#         exit()
#
#     print("\n--- Phase 2.1: Setup and Initial Loading Complete ---")
#     print(f"  Original WSI: {os.path.basename(ORIGINAL_WSI_PATH)}")
#     print(f"  Base WSI Magnification: {base_wsi_magnification}x")
#     print(f"  Target Analysis Magnification: {TARGET_MAGNIFICATION}x")
#     print(f"  Patch Size: {PATCH_SIZE}x{PATCH_SIZE} pixels")
#     print(f"  Instance Mask (Stage 1): {TARGET_INSTANCE_MASK_FILENAME} (shape: {oyster_instance_mask_stage1_res.shape})")
#     print(f"  Stage 1 Downsample Factor (for mask scaling): {STAGE1_DOWNSAMPLE_FACTOR}")
#
#     best_level_for_patches = -1
#     actual_downsample_at_level = -1.0
#     effective_magnification = -1.0
#     dimensions_of_patching_level = (0,0)
#
#     if base_wsi_magnification and TARGET_MAGNIFICATION and wsi_level_downsamples:
#         try:
#             # Use helper function with the loaded downsamples
#             best_level_for_patches, actual_downsample_at_level = get_level_for_target_mag(
#                 base_wsi_magnification,
#                 TARGET_MAGNIFICATION,
#                 wsi_level_downsamples  # Pass the list of downsamples we got from tifffile processing
#             )
#             effective_magnification = base_wsi_magnification / actual_downsample_at_level
#             dimensions_of_patching_level = wsi_level_dimensions[best_level_for_patches]
#
#             print(f"\nPatching Info:")
#             print(
#                 f"\tTarget downsample for {TARGET_MAGNIFICATION}x: {base_wsi_magnification / TARGET_MAGNIFICATION:.2f}")
#             print(
#                 f"\tBest WSI level index for patching: {best_level_for_patches} (actual downsample: {actual_downsample_at_level:.2f})")
#             print(f"\tEffective magnification at this level: {effective_magnification:.2f}x")
#             print(f"\tDimensions of this level (W,H): {dimensions_of_patching_level}")
#         except Exception as e:
#             print(f"Error calculating best level: {e}. Exiting.")
#             wsi_file_obj.close()
#             exit()
#
#             # print(f"Error calculating best level: {e}. Defaulting to level 0.")
#             # best_level_for_patches = 0
#             # actual_downsample_at_level = wsi_level_downsamples[0] if wsi_level_downsamples else 1.0
#             # effective_magnification = base_wsi_magnification / actual_downsample_at_level
#             # dimensions_of_patching_level = wsi_level_dimensions[0] if wsi_level_dimensions else (0, 0)
#     else:
#         print("Could not determine best patching level due to missing magnification or downsample info.")
#         wsi_file_obj.close()
#         exit()
#
#     # test_level_idx = 0  # Try 0, then maybe 2, etc.
#     # print(f"DEBUG: Attempting to read level {test_level_idx} directly...")
#     # try:
#     #     debug_level_data = wsi_file_obj.series[0].levels[test_level_idx].asarray()
#     #     print(f"DEBUG: Successfully read level {test_level_idx}, shape: {debug_level_data.shape}")
#     #     # You could try to plot this debug_level_data if it's not too huge
#     # except Exception as e_debug:
#     #     print(f"DEBUG: Error reading level {test_level_idx}: {e_debug}")
#
#     # --- MASK SCALING (to the chosen best_level_for_patches resolution) ---
#     scaled_instance_mask_for_patching_binary = None
#     if actual_downsample_at_level > 0:
#         print(f"\nScaling Stage 1 mask to the resolution of WSI Level {best_level_for_patches}...")
#         # dimensions_of_patching_level is (Width, Height)
#         scaled_instance_mask_for_patching = cv2.resize(
#             oyster_instance_mask_stage1_res,
#             (dimensions_of_patching_level[0], dimensions_of_patching_level[1]),
#             # cv2.resize dsize is (width, height)
#             interpolation=cv2.INTER_NEAREST
#         )
#         _, scaled_instance_mask_for_patching_binary = cv2.threshold(
#             scaled_instance_mask_for_patching, 127, 255, cv2.THRESH_BINARY
#         )
#         print(
#             f"Scaled Stage 1 mask to Level {best_level_for_patches} resolution, new shape: {scaled_instance_mask_for_patching_binary.shape}"
#         )
#
#         if ENABLE_PLOTTING:
#             try:
#                 # Load the actual image plane we will be patching from for visualization
#                 image_plane_for_patching = wsi_file_obj.series[0].levels[best_level_for_patches].asarray()
#                 if image_plane_for_patching.ndim == 3 and image_plane_for_patching.shape[2] == 4:  # RGBA
#                     image_plane_for_patching = cv2.cvtColor(image_plane_for_patching, cv2.COLOR_RGBA2RGB)
#                 elif image_plane_for_patching.ndim == 2:  # Grayscale
#                     image_plane_for_patching = cv2.cvtColor(image_plane_for_patching, cv2.COLOR_GRAY2RGB)
#                 # May need other conversions (e.g. if image_plane_for_patching.shape[2] == 1)
#
#                 plt.figure(figsize=(12, 12))
#                 overlay_viz = image_plane_for_patching.copy()
#                 # Ensure mask_viz_rgb is created correctly for overlay
#                 mask_for_viz_rgb = np.zeros_like(image_plane_for_patching)
#                 mask_for_viz_rgb[scaled_instance_mask_for_patching_binary == 255] = [255, 0,
#                                                                                      0]  # Red where mask is white
#
#                 alpha = 0.3
#                 cv2.addWeighted(mask_for_viz_rgb, alpha, overlay_viz, 1 - alpha, 0, overlay_viz)
#                 plt.imshow(overlay_viz)
#                 plt.title(
#                     f"Scaled Stage 1 Mask Overlaid on Patching Level {best_level_for_patches} (~{effective_magnification:.2f}x)")
#                 plt.show()
#             except Exception as e_plot:
#                 print(f"Error generating overlay plot for scaled mask: {e_plot}")
#     else:
#         print("Could not perform mask scaling due to invalid actual_downsample_at_level.")
#         wsi_file_obj.close()
#         exit()
#     # --- END MASK SCALING ---
#
#     # --- Load the entire image plane for patching ONCE ---
#     image_plane_for_patching = None
#     if best_level_for_patches != -1:  # Check if best_level was determined
#         print(f"\nLoading entire image plane for WSI Level {best_level_for_patches} for patching...")
#         try:
#             image_plane_for_patching = wsi_file_obj.series[0].levels[best_level_for_patches].asarray()
#             if image_plane_for_patching.ndim == 3 and image_plane_for_patching.shape[2] == 4:  # RGBA
#                 image_plane_for_patching = cv2.cvtColor(image_plane_for_patching, cv2.COLOR_RGBA2RGB)
#             elif image_plane_for_patching.ndim == 2:  # Grayscale
#                 image_plane_for_patching = cv2.cvtColor(image_plane_for_patching, cv2.COLOR_GRAY2RGB)
#             print(f"Successfully loaded image plane for patching, shape: {image_plane_for_patching.shape}")
#
#             if ENABLE_PLOTTING:  # Show overlay plot
#                 plt.figure(figsize=(12, 12))
#                 overlay_viz = image_plane_for_patching.copy()
#                 mask_for_viz_rgb = np.zeros_like(image_plane_for_patching)
#                 mask_for_viz_rgb[scaled_instance_mask_for_patching_binary == 255] = [255, 0, 0]
#                 alpha = 0.3
#                 cv2.addWeighted(mask_for_viz_rgb, alpha, overlay_viz, 1 - alpha, 0, overlay_viz)
#                 plt.imshow(overlay_viz)
#                 plt.title(
#                     f"Scaled Stage 1 Mask Overlaid on Patching Level {best_level_for_patches} (~{effective_magnification:.2f}x)")
#                 plt.show()
#         except Exception as e_load_plane:
#             print(f"🛑 Error loading entire image plane for level {best_level_for_patches}: {e_load_plane}")
#             image_plane_for_patching = None  # Ensure it's None if loading failed
#     else:
#         print(f"🛑 Invalid best_level_for_patches: {best_level_for_patches}")
#
#     if image_plane_for_patching is None:
#         print("🛑 Cannot proceed with patching as the image plane could not be loaded. Exiting.")
#         wsi_file_obj.close()
#         exit()
#     # --- End loading image plane for patching ---
#
#     print("\n--- Phase 2.2: Generating Patch Coordinates and Extracting Patches ---")
#
#     valid_patches_info = []  # Store dicts with coords and patch data
#
#     level_height = dimensions_of_patching_level[1]  # From earlier calculation
#     level_width = dimensions_of_patching_level[0]  # From earlier calculation
#
#     step_size = PATCH_SIZE - PATCH_OVERLAP
#     if step_size <= 0:
#         print(
#             f"🛑 Error: PATCH_OVERLAP ({PATCH_OVERLAP}) >= PATCH_SIZE ({PATCH_SIZE}). Step size would be non-positive.")
#         wsi_file_obj.close()
#         exit()
#
#     # Number of patches for verbose progress (optional)
#     num_potential_patches_y = (level_height - PATCH_SIZE) // step_size + 1 if level_height >= PATCH_SIZE else 0
#     num_potential_patches_x = (level_width - PATCH_SIZE) // step_size + 1 if level_width >= PATCH_SIZE else 0
#     total_potential_patches = num_potential_patches_y * num_potential_patches_x
#     print(f"Iterating over WSI Level {best_level_for_patches} (Dimensions: {level_width}x{level_height})")
#     print(f"Patch size: {PATCH_SIZE}x{PATCH_SIZE}, Step size: {step_size}")
#     print(f"Potential patches to check (approx): {total_potential_patches}")
#
#     patch_count = 0
#     valid_patch_count = 0
#     for y_coord in range(0, level_height - PATCH_SIZE + 1, step_size):
#         for x_coord in range(0, level_width - PATCH_SIZE + 1, step_size):
#             patch_count += 1
#             if patch_count % 1000 == 0:  # Adjusted progress print frequency
#                 print(f"  Checked {patch_count}/{total_potential_patches} potential patch locations...")
#
#             mask_patch_region = scaled_instance_mask_for_patching_binary[
#                                 y_coord: y_coord + PATCH_SIZE,
#                                 x_coord: x_coord + PATCH_SIZE
#                                 ]
#
#             tissue_threshold_pixels = (PATCH_SIZE * PATCH_SIZE) * 0.1
#             if cv2.countNonZero(mask_patch_region) > tissue_threshold_pixels:
#                 valid_patch_count += 1
#
#                 # Slice the pre-loaded image_plane_for_patching
#                 image_patch_data = image_plane_for_patching[
#                                    y_coord: y_coord + PATCH_SIZE,
#                                    x_coord: x_coord + PATCH_SIZE,
#                                    :  # Select all color channels if present
#                                    ]
#
#                 # Store coordinates and the patch data itself
#                 valid_patches_info.append({
#                     "x": x_coord, "y": y_coord,
#                     "level": best_level_for_patches,
#                     "patch_filename_prefix": f"patch_lvl{best_level_for_patches}_x{x_coord}_y{y_coord}",
#                     "data": image_patch_data  # Store the patch data
#                 })
#
#                 if ENABLE_PLOTTING and valid_patch_count <= 5:
#                     plt.figure(figsize=(5, 5))
#                     plt.imshow(image_patch_data)  # image_patch_data is already RGB
#                     plt.title(f"Valid Patch {valid_patch_count} (L{best_level_for_patches} @ {x_coord},{y_coord})")
#                     plt.axis('off')
#                     plt.show()
#
#     print(f"\nPatch generation complete.")
#     print(f"  Total potential patch locations checked: {patch_count}")
#     print(f"  Number of valid patches found: {len(valid_patches_info)}")
#     if valid_patches_info:
#         print(f"  (Displayed first {min(5, len(valid_patches_info))} valid patches for visualization)")
#
#         # --- Phase 2.3: Process Each Patch with SAM AutomaticMaskGenerator ---
#         print("\n--- Phase 2.3: Processing Patches with SAM AutomaticMaskGenerator ---")
#         # Create a subdirectory for this specific oyster instance's patch results
#         instance_output_dir = os.path.join(OUTPUT_DIR_STAGE2, os.path.splitext(TARGET_INSTANCE_MASK_FILENAME)[0])
#         os.makedirs(instance_output_dir, exist_ok=True)
#
#         # Limit processing for now to a few patches for quick testing
#         NUM_PATCHES = 10 # maybe move to configuration later
#         num_patches_to_process_with_sam = min(NUM_PATCHES, len(valid_patches_info))  # Process first 5 or fewer
#         print(f"Will process first {num_patches_to_process_with_sam} valid patches with SAM AutomaticMaskGenerator...")
#
#         for i, patch_info in enumerate(valid_patches_info[:num_patches_to_process_with_sam]):
#             patch_image = patch_info['data']
#             patch_filename_prefix = patch_info['patch_filename_prefix']
#             print(f"\nProcessing patch {i + 1}/{num_patches_to_process_with_sam}: {patch_filename_prefix}")
#
#             # SAM expects uint8 HWC images
#             if patch_image.dtype != np.uint8:
#                 print(f"  Patch dtype is {patch_image.dtype}, converting to uint8.")
#                 if patch_image.max() <= 1.0 and patch_image.min() >= 0.0:  # float 0-1
#                     patch_image_uint8 = (patch_image * 255).astype(np.uint8)
#                 else:  # General case
#                     patch_image_uint8 = np.clip(patch_image, 0, 255).astype(np.uint8)
#             else:
#                 patch_image_uint8 = patch_image
#
#             if patch_image_uint8.ndim == 3 and patch_image_uint8.shape[2] == 1:  # Grayscale with extra dim
#                 patch_image_uint8 = cv2.cvtColor(patch_image_uint8, cv2.COLOR_GRAY2RGB)
#             elif patch_image_uint8.ndim == 2:  # Grayscale
#                 patch_image_uint8 = cv2.cvtColor(patch_image_uint8, cv2.COLOR_GRAY2RGB)
#
#             if sam_mask_generator:
#                 print(f"  Running SAM AutomaticMaskGenerator on patch...")
#                 generated_masks_anns = sam_mask_generator.generate(patch_image_uint8)
#                 print(f"  SAM generated {len(generated_masks_anns)} masks for this patch.")
#
#                 if generated_masks_anns:
#                     patch_output_sub_dir = os.path.join(instance_output_dir, patch_filename_prefix)
#                     os.makedirs(patch_output_sub_dir, exist_ok=True)
#
#                     # Save individual masks as PNGs
#                     for j, ann in enumerate(generated_masks_anns):
#                         mask_data = ann['segmentation']  # boolean mask
#                         # Include area and predicted_iou in filename for easier sorting/filtering later
#                         mask_save_path = os.path.join(
#                             patch_output_sub_dir,
#                             f"mask_{j:03d}_area_{ann['area']}_iou_{ann['predicted_iou']:.2f}.png"
#                         )
#                         cv2.imwrite(mask_save_path, mask_data.astype(np.uint8) * 255)
#                     print(f"  Saved {len(generated_masks_anns)} individual masks to {patch_output_sub_dir}")
#
#                     # Could save as JSON for metadata if needed
#
#                 if generated_masks_anns:
#                 # if ENABLE_PLOTTING and generated_masks_anns:
#                     fig, ax = plt.subplots(figsize=(8, 8))
#                     ax.imshow(patch_image_uint8)
#                     show_anns(generated_masks_anns, ax)  # Use the helper function
#                     ax.set_title(f"SAM Auto-Masks for {patch_filename_prefix}")
#                     ax.axis('off')
#                     # plt.show()
#                     plt.savefig(os.path.join(patch_output_sub_dir, patch_filename_prefix + "_plot.png"))
#                     print("Saved SAM mask overlay plot for this patch.")
#
#         print("\n--- Stage 2 SAM Processing (Limited Run) Complete ---")
#
#         if wsi_file_obj:
#             wsi_file_obj.close()
#             print("Closed WSI file object.")
